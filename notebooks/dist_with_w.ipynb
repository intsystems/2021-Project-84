{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-14T20:03:28.679996Z",
     "start_time": "2021-04-14T20:03:27.559160Z"
    },
    "id": "624Ky70AYVED"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../code')\n",
    "from resnet import *\n",
    "from cifar_very_tiny import *\n",
    "from cifar_tiny import *\n",
    "from cifar_dataset import *    \n",
    "import torch as t \n",
    "import numpy as np\n",
    "import tqdm\n",
    "import matplotlib.pylab as plt\n",
    "import matplotlib.cm as cm\n",
    "import json\n",
    "import hyperparams\n",
    "from importlib import reload\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize']=(12,9)\n",
    "plt.rcParams['font.size']= 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-14T20:03:31.029661Z",
     "start_time": "2021-04-14T20:03:28.692505Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 135,
     "referenced_widgets": [
      "53248d8fbab446d8a72db271cf823d95",
      "bedde58028144bacab1f4bfa8963bc8b",
      "850d3abafbe64e578a463a0a2db1bb99",
      "c978d46124164b9aaed7c1ff7b20310f",
      "17b7b0af2d0d44bd8ce06e58ace197a8",
      "e7529646346a4d739d233314cfce210c",
      "1d8bc56fc12e40889bd1df1483a0d73d",
      "e9d22b3f83974cc98264bb8305f6e9cd"
     ]
    },
    "id": "ukmqq2i5YVEF",
    "outputId": "1ad65227-b86e-4dc2-a757-893687bd5990"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# добавил в загрузку валидационную выборку\n",
    "# обрати внимание, maxsize --- это размер совокпного обучения и валидации\n",
    "# поэтому размер обучающей выборки совпадает с тем, что было до этого\n",
    "_, test_loader, train_loader_no_augumentation, valid_loader = cifar10_loader(batch_size=128, split_train_val=True,\n",
    "                                                                             maxsize=10112*2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-14T20:03:41.691628Z",
     "start_time": "2021-04-14T20:03:41.687483Z"
    },
    "id": "IvO4c1B3YVEG"
   },
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "epoch_num = 50\n",
    "run_num = 5 # количество запусков эксперимента\n",
    "# версия нужна, чтобы различать старые и новые результаты экспериментов. \n",
    "# менять нужно каждый раз, когда есть хотя бы незначительные изменения в эксперименте\n",
    "experiment_version = '18' \n",
    "\n",
    "validate_every_epoch = 5 # каждые 5 эпох отслеживать параметры модели\n",
    "\n",
    "# с этими гиперпараметрами мы начинаем эксперименты\n",
    "start_beta = 0.9914 #0.3 \n",
    "start_temp  = 6.5 #10**(0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-14T20:03:49.735130Z",
     "start_time": "2021-04-14T20:03:49.729487Z"
    },
    "id": "wsc9ercWYVEG"
   },
   "outputs": [],
   "source": [
    "def accuracy(student):\n",
    "        student.eval()\n",
    "        total = 0 \n",
    "        correct = 0\n",
    "        with t.no_grad():\n",
    "            for x,y in test_loader:\n",
    "                x = x.to(device)\n",
    "                y = y.to(device)\n",
    "                out = student(x)\n",
    "                correct += t.eq(t.argmax(out, 1), y).sum()\n",
    "                total+=len(x)\n",
    "        student.train()\n",
    "        return (correct/total).cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "llpZl0mvYVEH",
    "outputId": "b387c749-dd55-4c1b-98aa-d392a17455eb"
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-647be88b12dd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_num\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0minternal_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mstudent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCifar_Very_Tiny\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0moptim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstudent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mcrit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCrossEntropyLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mto\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    610\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    611\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 612\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    613\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    614\u001b[0m     def register_backward_hook(\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    357\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 359\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    360\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    379\u001b[0m                 \u001b[0;31m# `with torch.no_grad():`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 381\u001b[0;31m                     \u001b[0mparam_applied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    382\u001b[0m                 \u001b[0mshould_use_set_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mshould_use_set_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    608\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mconvert_to_format\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    609\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemory_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconvert_to_format\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 610\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    611\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    612\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# запуск без дистилляции\n",
    "for _ in range(run_num):\n",
    "    internal_results = []\n",
    "    student = Cifar_Very_Tiny(10).to(device)\n",
    "    optim = t.optim.Adam(student.parameters())    \n",
    "    crit = nn.CrossEntropyLoss()\n",
    "    for e in range(epoch_num):\n",
    "        tq = tqdm.tqdm(train_loader_no_augumentation)\n",
    "        losses = []\n",
    "        for x,y in tq:\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "            student.zero_grad()            \n",
    "            loss = crit(student(x), y)\n",
    "            losses.append(loss.cpu().detach().numpy())\n",
    "            loss.backward()\n",
    "            optim.step()\n",
    "            tq.set_description('current loss:{}'.format(np.mean(losses[-10:])))        \n",
    "        if e==0 or (e+1)%validate_every_epoch == 0: # если номер эпохи делится на 5 или эпоха - первая             \n",
    "            test_loss = []\n",
    "            student.eval()\n",
    "            for x,y in test_loader:\n",
    "                x = x.to(device)\n",
    "                y = y.to(device)                            \n",
    "                test_loss.append(crit(student(x), y).detach().cpu().numpy())                 \n",
    "            test_loss = float(np.mean(test_loss))\n",
    "            acc = float(accuracy(student))\n",
    "            student.train()\n",
    "            internal_results.append({'epoch': e, 'test loss':test_loss, 'accuracy':acc})\n",
    "            print (internal_results[-1])\n",
    "\n",
    "    with open('exp'+experiment_version+'_basic.jsonl', 'a') as out:\n",
    "        out.write(json.dumps({'results':internal_results, 'version': experiment_version})+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-14T20:03:54.872466Z",
     "start_time": "2021-04-14T20:03:54.868224Z"
    }
   },
   "outputs": [],
   "source": [
    "kl = nn.KLDivLoss(reduction='batchmean')\n",
    "sm = nn.Softmax(dim=1)\n",
    "\n",
    "def distill(out, batch_logits, temp):\n",
    "    g = sm(out/temp)\n",
    "    f = F.log_softmax(batch_logits/temp)    \n",
    "    return kl(f, g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "KyzIp3KSenYi"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './logits_cnn.npy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-c90f4dedb87e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Запуск --- с CNN-дистилляцией\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# в качестве значений гиперпараметров ставим  start_beta, start_temp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./logits_cnn.npy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_num\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0minternal_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[1;32m    426\u001b[0m         \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 428\u001b[0;31m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos_fspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    429\u001b[0m         \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    430\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './logits_cnn.npy'"
     ]
    }
   ],
   "source": [
    "# Запуск --- с CNN-дистилляцией\n",
    "# в качестве значений гиперпараметров ставим  start_beta, start_temp\n",
    "logits = np.load('./logits_cnn.npy')\n",
    "for _ in range(run_num):\n",
    "    internal_results = []\n",
    "    beta = start_beta\n",
    "    temp = start_temp\n",
    "    student = Cifar_Very_Tiny(10).to(device)\n",
    "    optim = t.optim.Adam(student.parameters())   \n",
    "    crit = nn.CrossEntropyLoss()\n",
    "    for e in range(epoch_num):\n",
    "        tq = tqdm.tqdm(train_loader_no_augumentation)\n",
    "        losses = []\n",
    "        for batch_id, (x,y) in enumerate(tq):\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)            \n",
    "            batch_logits = t.Tensor(logits[128*batch_id:128*(batch_id+1)]).to(device)            \n",
    "            student.zero_grad()\n",
    "            out = student(x)\n",
    "            student_loss = crit(out, y)            \n",
    "            distillation_loss = distill(out, batch_logits, temp)\n",
    "            loss = (1-beta) * student_loss + beta*distillation_loss\n",
    "            losses.append(loss.cpu().detach().numpy())\n",
    "            loss.backward()\n",
    "            optim.step()\n",
    "            tq.set_description('current loss:{}'.format(np.mean(losses[-10:])))\n",
    "        if e==0 or (e+1)%validate_every_epoch == 0: # если номер эпохи делится на 5 или эпоха - первая             \n",
    "            test_loss = []\n",
    "            student.eval()\n",
    "            for x,y in test_loader:\n",
    "                x = x.to(device)\n",
    "                y = y.to(device)                            \n",
    "                test_loss.append(crit(student(x), y).detach().cpu().numpy())                 \n",
    "            test_loss = float(np.mean(test_loss))\n",
    "            acc = float(accuracy(student))\n",
    "            student.train()\n",
    "            internal_results.append({'epoch': e, 'test loss':test_loss, 'accuracy':acc})\n",
    "            print (internal_results[-1])\n",
    "\n",
    "            \n",
    "    with open('exp'+experiment_version+'_distill.jsonl', 'a') as out:\n",
    "        out.write(json.dumps({'results':internal_results, 'version': experiment_version})+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Cifar_Tiny(\n",
       "  (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (conv1_bn): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv2): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (conv2_bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (conv3_bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (fc1): Linear(in_features=256, out_features=128, bias=True)\n",
       "  (fc2): Linear(in_features=128, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "teacher.get_features([0,2,4,6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-15T00:29:31.844102Z",
     "start_time": "2021-04-14T23:14:31.405152Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/79 [00:00<?, ?it/s]<ipython-input-6-cea0592a0b8b>:6: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  f = F.log_softmax(batch_logits/temp)\n",
      "current loss:8956.294921875: 100%|██████████| 79/79 [00:02<00:00, 30.98it/s]  \n",
      "current loss:8640.8662109375:   5%|▌         | 4/79 [00:00<00:02, 30.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 0, 'test loss': 2.3041396141052246, 'accuracy': 0.09999999403953552, 'temp': 2.699783742427826, 'beta1': 0.5665669441223145, 'beta2': 0.7055090069770813, 'beta3': 0.7055090069770813}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "current loss:6319.2509765625: 100%|██████████| 79/79 [00:02<00:00, 30.80it/s] \n",
      "current loss:4380.1240234375: 100%|██████████| 79/79 [00:02<00:00, 31.16it/s] \n",
      "current loss:3049.644287109375: 100%|██████████| 79/79 [00:02<00:00, 31.38it/s]\n",
      "current loss:2106.16455078125: 100%|██████████| 79/79 [00:02<00:00, 31.24it/s] \n",
      "current loss:2056.36181640625:   4%|▍         | 3/79 [00:00<00:02, 26.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 4, 'test loss': 2.290347099304199, 'accuracy': 0.09999999403953552, 'temp': 2.699783742427826, 'beta1': 0.5665669441223145, 'beta2': 0.7055090069770813, 'beta3': 0.7055090069770813}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "current loss:1444.6912841796875: 100%|██████████| 79/79 [00:02<00:00, 30.85it/s]\n",
      "current loss:992.6282958984375: 100%|██████████| 79/79 [00:02<00:00, 31.15it/s] \n",
      "current loss:685.8023681640625: 100%|██████████| 79/79 [00:02<00:00, 30.96it/s]\n",
      "current loss:479.0387268066406: 100%|██████████| 79/79 [00:02<00:00, 30.64it/s] \n",
      "current loss:338.35845947265625: 100%|██████████| 79/79 [00:02<00:00, 31.06it/s]\n",
      "current loss:330.5971374511719:   4%|▍         | 3/79 [00:00<00:02, 27.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 9, 'test loss': 2.2908222675323486, 'accuracy': 0.10679999738931656, 'temp': 2.699783742427826, 'beta1': 0.5665669441223145, 'beta2': 0.7055090069770813, 'beta3': 0.7055090069770813}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "current loss:242.14859008789062: 100%|██████████| 79/79 [00:02<00:00, 31.12it/s]\n",
      "current loss:175.82823181152344: 100%|██████████| 79/79 [00:02<00:00, 31.16it/s]\n",
      "current loss:129.56983947753906: 100%|██████████| 79/79 [00:02<00:00, 31.46it/s]\n",
      "current loss:97.01971435546875: 100%|██████████| 79/79 [00:02<00:00, 31.23it/s] \n",
      "current loss:73.92278289794922: 100%|██████████| 79/79 [00:02<00:00, 30.97it/s]\n",
      "current loss:71.55269622802734:   5%|▌         | 4/79 [00:00<00:02, 31.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 14, 'test loss': 2.304670810699463, 'accuracy': 0.10029999911785126, 'temp': 2.699783742427826, 'beta1': 0.5665669441223145, 'beta2': 0.7055090069770813, 'beta3': 0.7055090069770813}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "current loss:57.37443161010742: 100%|██████████| 79/79 [00:02<00:00, 31.28it/s] \n",
      "current loss:45.39491271972656: 100%|██████████| 79/79 [00:02<00:00, 30.93it/s] \n",
      "current loss:36.630767822265625: 100%|██████████| 79/79 [00:02<00:00, 30.62it/s]\n",
      "current loss:30.149276733398438: 100%|██████████| 79/79 [00:02<00:00, 31.07it/s]\n",
      "current loss:25.297693252563477: 100%|██████████| 79/79 [00:02<00:00, 31.39it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-39-28712b3d419f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0mtest_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m             \u001b[0mstudent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m                 \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m                 \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    433\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 435\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    436\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    473\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 475\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    476\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torchvision/datasets/cifar.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_transform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, pic)\u001b[0m\n\u001b[1;32m     90\u001b[0m             \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mConverted\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \"\"\"\n\u001b[0;32m---> 92\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py\u001b[0m in \u001b[0;36mto_tensor\u001b[0;34m(pic)\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mByteTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m255\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Запуск --- со случаными значениями гиперпараметров\n",
    "crit = nn.CrossEntropyLoss()\n",
    "\n",
    "# определяем функцию потерь как замкнутую относительно аргументов функцию\n",
    "# нужно для подсчета градиентов гиперпараметров по двухуровневой оптимизации\n",
    "def param_loss(batch,model, h):\n",
    "    x,y,batch_logits,t_features, s_features, w = batch    \n",
    "    beta,beta2,beta3,temp = h\n",
    "    out = model(x)\n",
    "    beta = F.sigmoid(beta)\n",
    "    beta2 = F.sigmoid(beta2)\n",
    "    beta3 = F.sigmoid(beta3)/100\n",
    "    \n",
    "    temp = F.sigmoid(temp) * 10\n",
    "    distillation_loss = distill(out, batch_logits, temp)\n",
    "    student_loss = crit(out, y)                \n",
    "    \n",
    "    w_loss = 0\n",
    "    for i in range(4):        \n",
    "        w_loss += t.sum((t.matmul(s_features[i], w[i]) -  t_features[i])**2, 1).mean()\n",
    "        \n",
    "        \n",
    "    loss = beta * distillation_loss + beta2 * student_loss + w_loss * beta3\n",
    "    \n",
    "    return loss\n",
    "\n",
    "logits = np.load('../code/logits_cnn.npy')\n",
    "teacher = Cifar_Tiny(10).to(device)\n",
    "teacher.load_state_dict(t.load('../code/aux_pkt.model?raw=true', map_location=device), )\n",
    "\n",
    "for _ in range(run_num):\n",
    "    internal_results = []\n",
    "    \n",
    "    # теперь beta и temp - не числа, а тензоры, по которым можно считать градиент\n",
    "    beta1 = t.nn.Parameter(t.tensor(np.random.uniform(low=-1, high=1), device=device), requires_grad=True)\n",
    "    beta2 = t.nn.Parameter(t.tensor(np.random.uniform(low=-1, high=1), device=device), requires_grad=True)\n",
    "    beta3 = t.nn.Parameter(t.tensor(np.random.uniform(low=-1, high=1), device=device), requires_grad=True)\n",
    "    temp = t.nn.Parameter(t.tensor(np.random.uniform(low=-2, high=0), device=device), requires_grad=True)    \n",
    "    h = [beta1, beta2, beta3, temp]\n",
    "    \n",
    "    \n",
    "    student = Cifar_Very_Tiny(10).to(device)\n",
    "    optim = t.optim.Adam(student.parameters())   \n",
    "    \n",
    "    for x,_ in train_loader_no_augumentation:\n",
    "        break\n",
    "    x = x.to(device)\n",
    "    w = []\n",
    "    f_in = student.get_features(x, [0,1,2,3])\n",
    "    f_out = teacher.get_features(x, [0,1,2,3])\n",
    "    for in_, out_ in zip(f_in, f_out):\n",
    "        w.append(t.randn(in_.shape[1], out_.shape[1]).cuda())\n",
    "    \n",
    "    for e in range(epoch_num): # хочется посмотреть куда сойдутся гиперпараметры, поэтому возьмем побольше эпох\n",
    "        tq = tqdm.tqdm(train_loader_no_augumentation)\n",
    "        losses = []\n",
    "        for batch_id, ((x,y)) in enumerate(tq):\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)            \n",
    "            batch_logits = t.Tensor(logits[128*batch_id:128*(batch_id+1)]).to(device) \n",
    "            \n",
    "            optim.zero_grad()\n",
    "            f_in = student.get_features(x, [0,1,2,3])\n",
    "            f_out = teacher.get_features(x, [0,1,2,3])\n",
    "    \n",
    "            loss = param_loss((x,y,batch_logits,f_out, f_in, w), student,h)\n",
    "            losses.append(loss.cpu().detach().numpy())\n",
    "            loss.backward()\n",
    "            optim.step()\n",
    "            tq.set_description('current loss:{}'.format(np.mean(losses[-10:])))\n",
    "        if e==0 or (e+1)%validate_every_epoch == 0: # если номер эпохи делится на 5 или эпоха - первая             \n",
    "            test_loss = []\n",
    "            student.eval()\n",
    "            for x,y in test_loader:\n",
    "                x = x.to(device)\n",
    "                y = y.to(device)                            \n",
    "                test_loss.append(crit(student(x), y).detach().cpu().numpy())                 \n",
    "            test_loss = float(np.mean(test_loss))\n",
    "            \n",
    "            \n",
    "            acc = float(accuracy(student))\n",
    "            student.train()\n",
    "            internal_results.append({'epoch': e, 'test loss':test_loss, 'accuracy':acc, \n",
    "                                     'temp':float(10*F.sigmoid(h[2]).cpu().detach().numpy()),\n",
    "                                     'beta1':float(F.sigmoid(h[0]).cpu().detach().numpy()),\n",
    "                                     'beta2':float(F.sigmoid(h[1]).cpu().detach().numpy()),\n",
    "                                    'beta3':float(F.sigmoid(h[1]).cpu().detach().numpy())})\n",
    "            \n",
    "            print (internal_results[-1])\n",
    "\n",
    "            \n",
    "    with open('exp'+experiment_version+'_w_dist_h_rand.jsonl', 'a') as out:\n",
    "        out.write(json.dumps({'results':internal_results, 'version': experiment_version})+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[-0.7514,  0.1773, -0.4779,  ...,  0.3393, -0.3660,  0.2624],\n",
       "         [-0.8842, -0.1683,  0.4462,  ...,  3.1425,  0.3287, -0.6552],\n",
       "         [-0.8631, -0.1994,  0.2775,  ..., -0.6473, -0.7569, -0.4378],\n",
       "         ...,\n",
       "         [ 0.8663, -1.7815,  1.3069,  ..., -0.0480, -0.7634, -0.4520],\n",
       "         [ 0.5320,  0.3822, -0.8424,  ..., -0.4680, -1.6757, -0.2089],\n",
       "         [ 0.9002, -1.2314,  0.3657,  ..., -0.7398,  0.0684, -0.9744]]),\n",
       " tensor([[-0.0401,  0.1368,  0.9736,  ...,  0.7400,  0.0514, -0.0842],\n",
       "         [-0.3874, -0.7632, -0.0408,  ...,  0.5974,  0.1077, -0.4998],\n",
       "         [-0.5327,  0.4283,  1.5127,  ..., -0.3498, -0.0648, -0.5655],\n",
       "         ...,\n",
       "         [-0.7716, -0.9684, -1.2373,  ..., -0.0454,  0.4990,  0.7507],\n",
       "         [-1.0290,  0.3870, -1.4709,  ..., -0.0779, -0.4832,  1.4097],\n",
       "         [-0.9672,  1.9007, -0.3325,  ..., -1.5615, -0.7924,  0.3367]]),\n",
       " tensor([[ 1.4746, -0.5375, -1.9071,  ..., -0.2746, -1.1300,  1.0408],\n",
       "         [ 1.0869,  2.0572,  0.8932,  ...,  1.0552, -1.2335, -0.4705],\n",
       "         [-0.2371, -0.9415, -0.5536,  ..., -0.5431, -0.3956,  0.8316],\n",
       "         ...,\n",
       "         [ 0.8305, -1.1679,  0.9397,  ..., -0.1553,  1.7760,  0.2608],\n",
       "         [ 0.0913,  0.2550, -0.8112,  ...,  0.8305,  0.3849, -0.2260],\n",
       "         [ 0.0895,  0.4662, -1.5778,  ...,  0.5898, -0.8075, -0.9336]]),\n",
       " tensor([[ 1.9913,  0.1896, -0.2747,  ..., -0.0664, -0.5547,  1.4032],\n",
       "         [-1.3165,  0.5881, -0.4844,  ...,  0.9106,  0.7928,  0.8783],\n",
       "         [-0.7153, -1.5911,  0.6713,  ..., -0.9467,  0.2309,  2.7319],\n",
       "         ...,\n",
       "         [ 0.7090, -1.0392, -1.3997,  ..., -0.5424,  0.1957, -1.0807],\n",
       "         [ 1.4883,  1.6072, -0.6189,  ...,  0.5803, -0.1553, -0.8990],\n",
       "         [-0.2131,  0.8125,  0.4545,  ..., -0.9400, -0.6627, -2.1298]])]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-04-15T13:25:36.633Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]<ipython-input-6-cea0592a0b8b>:6: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  f = F.log_softmax(batch_logits/temp)\n",
      "current loss:228.1383819580078: : 79it [00:05, 13.50it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1346006393432617\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "current loss:225.26449584960938: : 2it [00:00, 13.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 0, 'test loss': 2.132808208465576, 'accuracy': 0.204599991440773, 'temp': 2.129318678379059, 'beta1': 0.4880298376083374, 'beta2': 0.7217536568641663, 'beta3': 0.7007215619087219}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "current loss:162.95828247070312: : 79it [00:05, 13.65it/s]\n",
      "current loss:116.46406555175781: : 79it [00:05, 13.76it/s]\n",
      "current loss:82.61605072021484: : 79it [00:05, 13.75it/s] \n",
      "current loss:58.85979461669922: : 79it [00:05, 13.77it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.8675687313079834\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "current loss:59.263771057128906: : 2it [00:00, 13.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 4, 'test loss': 1.8707540035247803, 'accuracy': 0.2921999990940094, 'temp': 1.2544663459062577, 'beta1': 0.5404069423675537, 'beta2': 0.7507766485214233, 'beta3': 0.7007215619087219}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "current loss:43.63921356201172: : 79it [00:05, 13.77it/s] \n",
      "current loss:36.539329528808594: : 79it [00:05, 13.45it/s]\n",
      "current loss:22.653362274169922: : 79it [00:05, 13.48it/s]\n",
      "current loss:18.780595779418945: : 79it [00:05, 13.57it/s]\n",
      "current loss:15.52271842956543: : 79it [00:05, 13.62it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.102837085723877\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "current loss:15.90566635131836: : 2it [00:00, 12.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 9, 'test loss': 2.10451078414917, 'accuracy': 0.24939998984336853, 'temp': 4.356904476881027, 'beta1': 0.6707221269607544, 'beta2': 0.80565345287323, 'beta3': 0.7007215619087219}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "current loss:13.205431938171387: : 79it [00:05, 13.53it/s]\n",
      "current loss:11.421762466430664: : 79it [00:05, 13.61it/s]\n",
      "current loss:10.018226623535156: : 79it [00:05, 13.65it/s]\n",
      "current loss:8.90816593170166: : 79it [00:05, 13.68it/s] \n",
      "current loss:8.020467758178711: : 79it [00:05, 13.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1593198776245117\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "current loss:8.231345176696777: : 2it [00:00, 12.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 14, 'test loss': 2.1594324111938477, 'accuracy': 0.19999998807907104, 'temp': 3.7231019735336304, 'beta1': 0.6860544681549072, 'beta2': 0.8415436148643494, 'beta3': 0.7007215619087219}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "current loss:7.310000419616699: : 79it [00:05, 13.58it/s] \n",
      "current loss:6.738398551940918: : 79it [00:05, 13.68it/s] \n",
      "current loss:6.287932395935059: : 79it [00:05, 13.61it/s] \n",
      "current loss:5.9333086013793945: : 79it [00:05, 13.70it/s]\n",
      "current loss:5.65286922454834: : 79it [00:05, 13.87it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1667041778564453\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "current loss:5.759459495544434: : 2it [00:00, 12.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 19, 'test loss': 2.1613965034484863, 'accuracy': 0.18769998848438263, 'temp': 3.1235377341508865, 'beta1': 0.699241042137146, 'beta2': 0.8607771396636963, 'beta3': 0.7007215619087219}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "current loss:5.434043884277344: : 79it [00:05, 13.53it/s] \n",
      "current loss:5.279083251953125: : 79it [00:05, 13.47it/s] \n",
      "current loss:5.1768269538879395: : 79it [00:05, 13.67it/s]\n",
      "current loss:5.122745990753174: : 79it [00:05, 13.59it/s] \n",
      "current loss:5.111889839172363: : 79it [00:05, 13.58it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1573472023010254\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "current loss:5.159760475158691: : 2it [00:00, 13.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 24, 'test loss': 2.1618847846984863, 'accuracy': 0.19859999418258667, 'temp': 2.532135121524334, 'beta1': 0.711664080619812, 'beta2': 0.8712711930274963, 'beta3': 0.7007215619087219}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "current loss:4.939513683319092: : 44it [00:03, 13.32it/s] \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-51-8e80f97b0bac>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     86\u001b[0m             \u001b[0mf_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mteacher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m             \u001b[0mhyper_grad_calc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalc_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_logits\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mf_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf_in\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mv_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m             \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_grad_value_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mh_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/reps/2021-Project-84/code/hyperparams.py\u001b[0m in \u001b[0;36mcalc_gradients\u001b[0;34m(self, trn, val)\u001b[0m\n\u001b[1;32m    119\u001b[0m         \u001b[0mdw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mv_grads\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m         \u001b[0mhessian\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_hessian\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0;31m# update final gradient = dalpha - xi*hessian\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/reps/2021-Project-84/code/hyperparams.py\u001b[0m in \u001b[0;36mcompute_hessian\u001b[0;34m(self, dw, trn)\u001b[0m\n\u001b[1;32m    149\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m                 \u001b[0mp\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m2.\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0meps\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 151\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mw_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    152\u001b[0m         \u001b[0mdalpha_neg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# dalpha { L_trn(w-) }\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-51-8e80f97b0bac>\u001b[0m in \u001b[0;36mparam_loss\u001b[0;34m(batch, model, h)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_logits\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mt_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mbeta\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbeta2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbeta3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtemp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mbeta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mbeta2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/reps/2021-Project-84/code/cifar_very_tiny.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     37\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv3_bn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_pool2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    772\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_buffers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    773\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0m_buffers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 774\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0;34m'_modules'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    775\u001b[0m             \u001b[0mmodules\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'_modules'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    776\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Запуск --- с CNN-дистилляцией и оптимизацией гиперпараметров, 2-beta\n",
    "crit = nn.CrossEntropyLoss()\n",
    "# определяем функцию потерь как замкнутую относительно аргументов функцию\n",
    "# нужно для подсчета градиентов гиперпараметров по двухуровневой оптимизации\n",
    "def param_loss(batch,model, h):\n",
    "    x,y,batch_logits,t_features, s_features, w = batch    \n",
    "    beta,beta2,beta3,temp = h\n",
    "    out = model(x)\n",
    "    beta = F.sigmoid(beta)\n",
    "    beta2 = F.sigmoid(beta2)\n",
    "    beta3 = F.sigmoid(beta3)/10000\n",
    "    \n",
    "    temp = F.sigmoid(temp) * 10\n",
    "    distillation_loss = distill(out, batch_logits, temp)\n",
    "    student_loss = crit(out, y)                \n",
    "    \n",
    "    w_loss = 0\n",
    "    for i in range(4):        \n",
    "        w_loss += t.sum((t.matmul(s_features[i], w[i]) -  t_features[i])**2, 1).mean()\n",
    "        \n",
    "        \n",
    "    loss = beta * distillation_loss + beta2 * student_loss + w_loss * beta3\n",
    "    \n",
    "    return loss\n",
    "\n",
    "# определяем функцию валидационную функцию потерь как замкнутую относительно аргументов функцию\n",
    "# нужно для подсчета градиентов гиперпараметров по двухуровневой оптимизации\n",
    "def hyperparam_loss(batch, model):\n",
    "    x,y = batch\n",
    "    out = model(x)\n",
    "    student_loss = crit(out, y)            \n",
    "    return student_loss\n",
    "\n",
    "hist = []\n",
    "logits = np.load('../code/logits_cnn.npy')\n",
    "teacher.eval()\n",
    "for _ in range(run_num):\n",
    "    internal_results = []    \n",
    "    # теперь beta и temp - не числа, а тензоры, по которым можно считать градиент\n",
    "    beta1 = t.nn.Parameter(t.tensor(np.random.uniform(low=-1, high=1), device=device), requires_grad=True)\n",
    "    beta2 = t.nn.Parameter(t.tensor(np.random.uniform(low=-1, high=1), device=device), requires_grad=True)\n",
    "    beta3 = t.nn.Parameter(t.tensor(np.random.uniform(low=-1, high=1), device=device), requires_grad=True)\n",
    "    temp = t.nn.Parameter(t.tensor(np.random.uniform(low=-2, high=0), device=device), requires_grad=True)    \n",
    "    h = [beta1, beta2, beta3, temp]\n",
    "    \n",
    "    student = Cifar_Very_Tiny(10).to(device)\n",
    "    optim = t.optim.Adam(list(student.parameters())+ w)\n",
    "    \n",
    "    # параметры Adam и функцию подсчета градиента \n",
    "    # взял из статьи по DARTS (выбор архитектуры сети градиентными методами)\n",
    "    # там также используется оптимизация гиперпараметров\n",
    "    \n",
    "    for x,_ in train_loader_no_augumentation:\n",
    "        break\n",
    "    x = x.to(device)\n",
    "    w = []\n",
    "    f_in = student.get_features(x, [0,1,2,3])\n",
    "    f_out = teacher.get_features(x, [0,1,2,3])\n",
    "    for in_, out_ in zip(f_in, f_out):\n",
    "        w.append(t.randn(in_.shape[1], out_.shape[1]).cuda())\n",
    "    \n",
    "    \n",
    "    optim2 = t.optim.SGD(h,  lr=10e4)   \n",
    "    hyper_grad_calc = hyperparams.AdamHyperGradCalculator(student, param_loss, hyperparam_loss, optim, h)\n",
    "    \n",
    "    crit = t.nn.CrossEntropyLoss()\n",
    "\n",
    "    for e in range(epoch_num): # хочется посмотреть куда сойдутся гиперпараметры, поэтому возьмем побольше эпох\n",
    "        \n",
    "        \n",
    "        tq = tqdm.tqdm(zip(train_loader_no_augumentation, valid_loader))\n",
    "        losses = []\n",
    "        for batch_id, ((x,y), (v_x, v_y)) in enumerate(tq):\n",
    "       \n",
    "            x = x.to(device)\n",
    "            y = y.to(device)            \n",
    "                      \n",
    "            batch_logits = t.Tensor(logits[128*batch_id:128*(batch_id+1)]).to(device) \n",
    "            # если настала пора понаблюдать за траекторий гиперпараметров\n",
    "          \n",
    "            #print (batch_id, 'train mini')\n",
    "            v_x = v_x.to(device)\n",
    "            v_y = v_y.to(device)  \n",
    "            optim2.zero_grad()            \n",
    "            f_in = student.get_features(x, [0,1,2,3])\n",
    "            f_out = teacher.get_features(x, [0,1,2,3])\n",
    "    \n",
    "            hyper_grad_calc.calc_gradients((x,y,batch_logits,f_out, f_in, w), (v_x, v_y))    \n",
    "            t.nn.utils.clip_grad_value_(h, 1.0)\n",
    "            for h_ in h:\n",
    "                h_.grad = t.where(t.isnan(h_.grad), t.zeros_like(h_.grad), h_.grad)  \n",
    "\n",
    "            optim2.step()                         \n",
    "            optim.zero_grad()\n",
    "            f_in = student.get_features(x, [0,1,2,3])\n",
    "            f_out = teacher.get_features(x, [0,1,2,3])\n",
    "    \n",
    "            loss = param_loss((x,y,batch_logits,f_out, f_in, w), student,h)\n",
    "        \n",
    "            losses.append(loss.cpu().detach().numpy())\n",
    "            loss.backward()\n",
    "            optim.step()\n",
    "            tq.set_description('current loss:{}'.format(np.mean(losses[-10:])))\n",
    "    \n",
    "        if e==0 or (e+1)%validate_every_epoch == 0: # если номер эпохи делится на 5 или эпоха - первая             \n",
    "            test_loss = []\n",
    "            student.eval()\n",
    "            for x,y in test_loader:\n",
    "                x = x.to(device)\n",
    "                y = y.to(device)                            \n",
    "                test_loss.append(crit(student(x), y).detach().cpu().numpy())                 \n",
    "            test_loss = float(np.mean(test_loss))\n",
    "            test_loss2 = []            \n",
    "            for x,y in test_loader:\n",
    "                x = x.to(device)\n",
    "                y = y.to(device)                            \n",
    "                test_loss2.append(crit(student(x), y).detach().cpu().numpy())                 \n",
    "            print (float(np.mean(test_loss2)))\n",
    "            \n",
    "            \n",
    "            acc = float(accuracy(student))\n",
    "            student.train()\n",
    "            internal_results.append({'epoch': e, 'test loss':test_loss, 'accuracy':acc, \n",
    "                                     'temp':float(0.1+9.9*F.sigmoid(h[3]).cpu().detach().numpy()),\n",
    "                                     'beta1':float(F.sigmoid(h[0]).cpu().detach().numpy()),\n",
    "                                     'beta2':float(F.sigmoid(h[1]).cpu().detach().numpy()),\n",
    "                                    'beta3':float(F.sigmoid(h[2]).cpu().detach().numpy())})\n",
    "            \n",
    "            print (internal_results[-1])\n",
    "\n",
    "            \n",
    "    with open('w_exp'+experiment_version+'_dist_h_b2_optim.jsonl', 'a') as out:\n",
    "        out.write(json.dumps({'results':internal_results, 'version': experiment_version})+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'exp6_basic.jsonl'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-2d02ab2b95ab>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"exp6_basic.jsonl\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mread_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mdata_b\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mread_file\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"exp6_distill.jsonl\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mread_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mdata_d\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mread_file\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"exp6_dist_h_rand.jsonl\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mread_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'exp6_basic.jsonl'"
     ]
    }
   ],
   "source": [
    "with open(\"exp6_basic.jsonl\", \"r\") as read_file:\n",
    "    data_b = [json.loads(line) for line in read_file]\n",
    "with open(\"exp6_distill.jsonl\", \"r\") as read_file:\n",
    "    data_d = [json.loads(line) for line in read_file]\n",
    "with open(\"exp6_dist_h_rand.jsonl\", \"r\") as read_file:\n",
    "    data_dr = [json.loads(line) for line in read_file]\n",
    "with open(\"exp6_dist_h_optim.jsonl\", \"r\") as read_file:\n",
    "    data_h = [json.loads(line) for line in read_file]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pylab as plt\n",
    "plt.rcParams['font.family'] = 'DejaVu Serif'\n",
    "plt.rcParams['lines.linewidth'] = 2\n",
    "plt.rcParams['lines.markersize'] = 12\n",
    "plt.rcParams['xtick.labelsize'] = 24\n",
    "plt.rcParams['ytick.labelsize'] = 24\n",
    "plt.rcParams['legend.fontsize'] = 24\n",
    "plt.rcParams['axes.titlesize'] = 36\n",
    "plt.rcParams['axes.labelsize'] = 24\n",
    "\n",
    "epoch_b = np.array([data_b[2]['results'][i]['epoch'] for i in range(len(data_b[0]['results']))])\n",
    "loss_b = np.array([subdata['results'][i]['test loss'] for i in range(len(data_b[0]['results'])) for subdata in data_b]).reshape(epoch_b.shape[0], -1)\n",
    "plt.plot(epoch_b, loss_b.mean(1), '-', color='red', label='без дистилляции')\n",
    "plt.fill_between(epoch_b, loss_b.mean(1)-loss_b.std(1), loss_b.mean(1)+loss_b.std(1), alpha=0.2, color='red')\n",
    "\n",
    "epoch_d = np.array([data_d[2]['results'][i]['epoch'] for i in range(len(data_d[2]['results']))])\n",
    "loss_d = np.array([subdata['results'][i]['test loss'] for i in range(len(data_d[0]['results'])) for subdata in data_d]).reshape(epoch_d.shape[0], -1)\n",
    "plt.plot(epoch_d, loss_d.mean(1), '-', color='blue', label='оптимальные гипепараметров')\n",
    "plt.fill_between(epoch_d, loss_d.mean(1)-loss_d.std(1), loss_d.mean(1)+loss_d.std(1), alpha=0.2, color='blue')\n",
    "\n",
    "epoch_dr = np.array([data_dr[2]['results'][i]['epoch'] for i in range(len(data_dr[2]['results']))])\n",
    "loss_dr = np.array([subdata['results'][i]['test loss'] for i in range(len(data_dr[0]['results'])) for subdata in data_dr]).reshape(epoch_dr.shape[0], -1)\n",
    "plt.plot(epoch_dr, loss_dr.mean(1), '-', color='black', label='случайные гипепараметры')\n",
    "plt.fill_between(epoch_dr, loss_dr.mean(1)-loss_dr.std(1), loss_dr.mean(1)+loss_dr.std(1), alpha=0.2, color='black')\n",
    "\n",
    "\n",
    "epoch_h = np.array([data_dr[2]['results'][i]['epoch'] for i in range(len(data_h[2]['results']))])\n",
    "loss_h = np.array([subdata['results'][i]['test loss'] for i in range(len(data_d[0]['results'])) for subdata in data_h]).reshape(epoch_h.shape[0], -1)\n",
    "plt.plot(epoch_h, loss_h.mean(1), '-', color='green', label='оптимизация гипепараметры')\n",
    "plt.fill_between(epoch_h, loss_h.mean(1)-loss_h.std(1), loss_h.mean(1)+loss_h.std(1), alpha=0.2, color='green')\n",
    "\n",
    "plt.xlabel('Количество эпох')\n",
    "plt.ylabel('Потеря на тестовой выборке')\n",
    "\n",
    "plt.legend()\n",
    "plt.savefig('loss.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_b = np.array([data_b[2]['results'][i]['epoch'] for i in range(len(data_b[0]['results']))])\n",
    "acc_b = np.array([subdata['results'][i]['accuracy'] for i in range(len(data_b[0]['results'])) for subdata in data_b]).reshape(epoch_b.shape[0], -1)\n",
    "plt.plot(epoch_b, acc_b.mean(1), '-', color='red', label='без дистилляции')\n",
    "plt.fill_between(epoch_b, acc_b.mean(1)-acc_b.std(1), acc_b.mean(1)+acc_b.std(1), alpha=0.2, color='red')\n",
    "\n",
    "epoch_d = np.array([data_d[2]['results'][i]['epoch'] for i in range(len(data_d[2]['results']))])\n",
    "acc_d = np.array([subdata['results'][i]['accuracy'] for i in range(len(data_d[0]['results'])) for subdata in data_d]).reshape(epoch_d.shape[0], -1)\n",
    "plt.plot(epoch_d, acc_d.mean(1), '-', color='blue', label='оптимальные гипепараметры')\n",
    "plt.fill_between(epoch_d, acc_d.mean(1)-acc_d.std(1), acc_d.mean(1)+acc_d.std(1), alpha=0.2, color='blue')\n",
    "\n",
    "epoch_h = np.array([data_h[2]['results'][i]['epoch'] for i in range(len(data_h[2]['results']))])\n",
    "acc_h = np.array([subdata['results'][i]['accuracy'] for i in range(len(data_d[0]['results'])) for subdata in data_h]).reshape(epoch_h.shape[0], -1)\n",
    "plt.plot(epoch_h, acc_h.mean(1), '-', color='green', label='оптимизация гиперпараметров')\n",
    "plt.fill_between(epoch_h, acc_h.mean(1)-acc_h.std(1), acc_h.mean(1)+acc_h.std(1), alpha=0.2, color='green')\n",
    "\n",
    "epoch_dr = np.array([data_dr[2]['results'][i]['epoch'] for i in range(len(data_dr[2]['results']))])\n",
    "acc_dr = np.array([subdata['results'][i]['accuracy'] for i in range(len(data_dr[0]['results'])) for subdata in data_dr]).reshape(epoch_h.shape[0], -1)\n",
    "plt.plot(epoch_dr, acc_dr.mean(1), '-', color='black', label='случайные гиперпараметры')\n",
    "plt.fill_between(epoch_dr, acc_dr.mean(1)-acc_h.std(1), acc_dr.mean(1)+acc_dr.std(1), alpha=0.2, color='black')\n",
    "\n",
    "\n",
    "plt.xlabel('Количество эпох')\n",
    "plt.ylabel('Точность классификации')\n",
    "plt.legend()\n",
    "plt.savefig('acc.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_b = np.hstack((epoch_b, epoch_b, epoch_b, epoch_b, epoch_b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_b = np.array([data_b[2]['results'][i]['epoch'] for i in range(len(data_b[0]['results']))])\n",
    "epoch_b.reshape(41, 1)\n",
    "epoch_b = np.hstack((epoch_b, epoch_b, epoch_b, epoch_b, epoch_b))\n",
    "loss_b = np.array([subdata['results'][i]['test loss'] for i in range(len(data_b[0]['results'])) for subdata in data_b]).reshape(epoch_b.shape[0], -1)\n",
    "plt.scatter(epoch_b, loss_b, color='red', marker='.', label='без дистилляции')\n",
    "#plt.fill_between(epoch_b, loss_b.mean(1)-loss_b.std(1), loss_b.mean(1)+loss_b.std(1), alpha=0.2, color='red')\n",
    "\n",
    "epoch_d = np.array([data_d[2]['results'][i]['epoch'] for i in range(len(data_d[2]['results']))])\n",
    "epoch_d.reshape(41, 1)\n",
    "epoch_d = np.hstack((epoch_d, epoch_d, epoch_d, epoch_d, epoch_d))\n",
    "loss_d = np.array([subdata['results'][i]['test loss'] for i in range(len(data_d[0]['results'])) for subdata in data_d]).reshape(epoch_d.shape[0], -1)\n",
    "plt.scatter(epoch_d, loss_d, marker='d', color='blue', label='оптимальные гипепараметры')\n",
    "#plt.fill_between(epoch_d, loss_d.mean(1)-loss_d.std(1), loss_d.mean(1)+loss_d.std(1), alpha=0.2, color='blue')\n",
    "\n",
    "epoch_dr = np.array([data_dr[2]['results'][i]['epoch'] for i in range(len(data_dr[2]['results']))])\n",
    "epoch_dr.reshape(41, 1)\n",
    "epoch_dr = np.hstack((epoch_dr, epoch_dr, epoch_dr, epoch_dr, epoch_dr))\n",
    "loss_dr = np.array([subdata['results'][i]['test loss'] for i in range(len(data_dr[0]['results'])) for subdata in data_dr]).reshape(epoch_dr.shape[0], -1)\n",
    "plt.scatter(epoch_dr, loss_dr, marker='x', color='black', label='случайные гипепараметры')\n",
    "#plt.fill_between(epoch_dr, loss_dr.mean(1)-loss_dr.std(1), loss_dr.mean(1)+loss_dr.std(1), alpha=0.2, color='black')\n",
    "\n",
    "\n",
    "epoch_h = np.array([data_dr[2]['results'][i]['epoch'] for i in range(len(data_h[2]['results']))])\n",
    "epoch_h.reshape(41, 1)\n",
    "epoch_h = np.hstack((epoch_h, epoch_h, epoch_h, epoch_h, epoch_h))\n",
    "loss_h = np.array([subdata['results'][i]['test loss'] for i in range(len(data_d[0]['results'])) for subdata in data_h]).reshape(epoch_h.shape[0], -1)\n",
    "plt.scatter(epoch_h, loss_h, marker='+', color='green', label='оптимизация гипепараметров')\n",
    "#plt.fill_between(epoch_h, loss_h.mean(1)-loss_h.std(1), loss_h.mean(1)+loss_h.std(1), alpha=0.2, color='green')\n",
    "\n",
    "plt.xlabel('Количество эпох')\n",
    "plt.ylabel('Потеря на тестовой выборке')\n",
    "plt.legend()\n",
    "plt.savefig('scatter_plot_loss.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_d = np.array([data_d[2]['results'][i]['epoch'] for i in range(len(data_d[2]['results']))])\n",
    "beta_d = np.array([data_d[2]['results'][i]['beta'] for i in range(len(data_d[2]['results']))])\n",
    "plt.plot(epoch_d, beta_d, '-', color='blue', label='дистилляция без оптимизации гипепараметров')\n",
    "plt.fill_between(epoch_d, beta_d-beta_d.std(), beta_d+beta_d.std(), alpha=0.2, color='blue')\n",
    "\n",
    "epoch_h = np.array([data_h[2]['results'][i]['epoch'] for i in range(len(data_h[2]['results']))])\n",
    "beta_h = np.array([data_h[2]['results'][i]['beta'] for i in range(len(data_h[2]['results']))])\n",
    "plt.plot(epoch_h, beta_h, '-', color='green', label='дистилляция с оптимизацией гипепараметров')\n",
    "plt.fill_between(epoch_h, beta_h-beta_h.std(), beta_h+beta_h.std(), alpha=0.2, color='green')\n",
    "\n",
    "plt.legend()\n",
    "plt.savefig('3.eps')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_d = np.array([data_d[2]['results'][i]['epoch'] for i in range(len(data_d[2]['results']))])\n",
    "temp_d = np.array([data_d[2]['results'][i]['temp'] for i in range(len(data_d[2]['results']))])\n",
    "plt.plot(epoch_d, temp_d, '-', color='blue', label='дистилляция без оптимизации гипепараметров')\n",
    "plt.fill_between(epoch_d, temp_d-temp_d.std(), temp_d+temp_d.std(), alpha=0.2, color='blue')\n",
    "\n",
    "epoch_h = np.array([data_h[2]['results'][i]['epoch'] for i in range(len(data_h[2]['results']))])\n",
    "temp_h = np.array([data_h[2]['results'][i]['temp'] for i in range(len(data_h[2]['results']))])\n",
    "plt.plot(epoch_h, temp_h, '-', color='green', label='дистилляция с оптимизацией гипепараметров')\n",
    "plt.fill_between(temp_h, temp_h-temp_h.std(), temp_h+temp_h.std(), alpha=0.2, color='green')\n",
    "\n",
    "plt.legend()\n",
    "plt.savefig('4.eps')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm.seismic(l[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_dr = np.array([subdata['results'][i]['accuracy'] for i in range(len(data_dr[0]['results'])) for subdata in data_dr]).reshape(epoch_dr.shape[0], -1)\n",
    "acc_h = np.array([subdata['results'][i]['accuracy'] for i in range(len(data_h[0]['results'])) for subdata in data_h]).reshape(epoch_h.shape[0], -1)\n",
    "all_results = list(acc_dr) + list(acc_h)\n",
    "max_ = np.max(all_results)\n",
    "min_ = np.min(all_results)\n",
    "\n",
    "colors = [cm.seismic((r-min_)/(max_-min_)) for r in acc_dr.flatten()]\n",
    "temp_dr = np.array([subdata['results'][i]['temp'] for i in range(len(data_dr[0]['results'])) for subdata in data_dr]).reshape(epoch_dr.shape[0], -1)\n",
    "beta_dr = np.array([subdata['results'][i]['beta'] for i in range(len(data_dr[0]['results'])) for subdata in data_dr]).reshape(epoch_dr.shape[0], -1)\n",
    "plt.scatter(beta_dr.flatten(), temp_dr.flatten(), marker='d', c=colors, label='случайные гипепараметры')\n",
    "\n",
    "colors = [cm.seismic((r-min_)/(max_-min_)) for r in acc_h.flatten()]\n",
    "temp_h = np.array([subdata['results'][i]['temp'] for i in range(len(data_h[0]['results'])) for subdata in data_h]).reshape(epoch_h.shape[0], -1)\n",
    "beta_h = np.array([subdata['results'][i]['beta'] for i in range(len(data_h[0]['results'])) for subdata in data_h]).reshape(epoch_h.shape[0], -1)\n",
    "plt.scatter(beta_h, temp_h, marker='x', c=colors, label='оптимизация гипепараметров')\n",
    "\n",
    "plt.xlabel('beta')\n",
    "plt.ylabel('$T_0$')\n",
    "plt.legend()\n",
    "plt.savefig('scatter_plot_beta_temp.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "P3e-QJ3RYVEH",
    "outputId": "ab55baa4-dde7-4c4b-feaa-edd180d4cff2"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "посмотреть, куда сходятся гиперпараметры.\n",
    "Задача скорее всего невыпуклая по гиперпараметрам, поэтому может быть несколько точек экстремума.\n",
    "\n",
    "Взять одно, наилучшее значение гиперпараметров.\n",
    "\n",
    "Посчитать дистилляцию БЕЗ оптимизации гиперпараметров с наилушчими значениями.\n",
    "\n",
    "НЕ ЗАБУДЬ ПОМЕНЯТЬ ИМЯ ФАЙЛА ДЛЯ СОХРАНЕНИЯ\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8das3HQtYVEI"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Посчитать дистилляцию с оптимизацей гиперпараметров, в качестве начальной точки взять не случайные значения,\n",
    "а start_beta, start_temp.\n",
    "\n",
    "НЕ ЗАБУДЬ ПОМЕНЯТЬ ИМЯ ФАЙЛА ДЛЯ СОХРАНЕНИЯ\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Построить график функции потерь на тесте в зависимости от эпохи. \n",
    "На графике должны быть линии для :\n",
    "    - оптимизации без дистилляции\n",
    "    - оптимизации с дистилляцией без оптимизации гиперпараметров, значения соответсвутют start_temp, start_beta\n",
    "    - оптимизации с дистилляцией без оптимизации гиперпараметров, значения соответсвутют оптимизированным значениям гиперпараметров\n",
    "    - оптимизации с дистилляцией c оптимизацией гиперпараметров, начальное приближение соответсвуeт start_temp, start_beta\n",
    "    - оптимизации с дистилляцией c оптимизацией гиперпараметров, начальное приближение случайное\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6oeb3wf-YVEI"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Построить график точности на тесте в зависимости от эпохи. \n",
    "На графике должны быть линии для :\n",
    "    - оптимизации без дистилляции\n",
    "    - оптимизации с дистилляцией без оптимизации гиперпараметров, значения соответсвутют start_temp, start_beta\n",
    "    - оптимизации с дистилляцией без оптимизации гиперпараметров, значения соответсвутют оптимизированным значениям гиперпараметров\n",
    "    - оптимизации с дистилляцией c оптимизацией гиперпараметров, начальное приближение соответсвуeт start_temp, start_beta\n",
    "    - оптимизации с дистилляцией c оптимизацией гиперпараметров, начальное приближение случайное\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Y5WBwGScYVEI"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Построить график беты в зависимости от эпохи. \n",
    "На графике должны быть линии для :    \n",
    "    - оптимизации с дистилляцией без оптимизации гиперпараметров, значения соответсвутют start_temp, start_beta\n",
    "    - оптимизации с дистилляцией без оптимизации гиперпараметров, значения соответсвутют оптимизированным значениям гиперпараметров\n",
    "    - оптимизации с дистилляцией c оптимизацией гиперпараметров, начальное приближение соответсвуeт start_temp, start_beta\n",
    "    - оптимизации с дистилляцией c оптимизацией гиперпараметров, начальное приближение случайное\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 569
    },
    "id": "JNqUHoMyYVEJ",
    "outputId": "eb8892b8-f681-4234-aadc-5f5e9c2835df",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Построить график температуры в зависимости от эпохи. \n",
    "На графике должны быть линии для :    \n",
    "    - оптимизации с дистилляцией без оптимизации гиперпараметров, значения соответсвутют start_temp, start_beta\n",
    "    - оптимизации с дистилляцией без оптимизации гиперпараметров, значения соответсвутют оптимизированным значениям гиперпараметров\n",
    "    - оптимизации с дистилляцией c оптимизацией гиперпараметров, начальное приближение соответсвуeт start_temp, start_beta\n",
    "    - оптимизации с дистилляцией c оптимизацией гиперпараметров, начальное приближение случайное\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "basic_distillation.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": true,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "17b7b0af2d0d44bd8ce06e58ace197a8": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "1d8bc56fc12e40889bd1df1483a0d73d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "53248d8fbab446d8a72db271cf823d95": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_850d3abafbe64e578a463a0a2db1bb99",
       "IPY_MODEL_c978d46124164b9aaed7c1ff7b20310f"
      ],
      "layout": "IPY_MODEL_bedde58028144bacab1f4bfa8963bc8b"
     }
    },
    "850d3abafbe64e578a463a0a2db1bb99": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e7529646346a4d739d233314cfce210c",
      "max": 170498071,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_17b7b0af2d0d44bd8ce06e58ace197a8",
      "value": 170498071
     }
    },
    "bedde58028144bacab1f4bfa8963bc8b": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c978d46124164b9aaed7c1ff7b20310f": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e9d22b3f83974cc98264bb8305f6e9cd",
      "placeholder": "​",
      "style": "IPY_MODEL_1d8bc56fc12e40889bd1df1483a0d73d",
      "value": " 170499072/? [05:33&lt;00:00, 511435.82it/s]"
     }
    },
    "e7529646346a4d739d233314cfce210c": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e9d22b3f83974cc98264bb8305f6e9cd": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
